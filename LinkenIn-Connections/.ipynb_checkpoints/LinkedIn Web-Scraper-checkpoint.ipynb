{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f6fc7ac",
   "metadata": {},
   "source": [
    "### LinkedIn Web Scraper\n",
    "\n",
    "This project scraps the LinkedIn site looking at connections of my account to store basic information including name, current role, past work experience, etc. The processed information is stored in a dataframe which could be exported as csv files for further data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1771dd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary modules for web scraping\n",
    "import requests, time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c667ade",
   "metadata": {},
   "source": [
    "\n",
    "Selenium is used for navigating the Chrome web driver. Beautiful soup is then used to extract the information for processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebf05e1",
   "metadata": {},
   "source": [
    "#### Initialise Chrome webdriver and login to personal account\n",
    "\n",
    "Input personal username and password in the relevant fields for login purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e06df49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access webdriver application\n",
    "PATH = \"C:/Program Files (x86)/chromedriver.exe\"\n",
    "browser = webdriver.Chrome(PATH)\n",
    "\n",
    "# Get to login page\n",
    "browser.get(\"https://www.linkedin.com/uas/login\")\n",
    "\n",
    "# Input username and password\n",
    "username=\"\"\n",
    "password=\"\"\n",
    "\n",
    "# Find html elements for username and password\n",
    "usernameID = browser.find_element_by_id('username')\n",
    "usernameID.send_keys(username)\n",
    "passwordID = browser.find_element_by_id('password')\n",
    "passwordID.send_keys(password)\n",
    "\n",
    "# Submit username and password for login\n",
    "passwordID.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70c4abb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to ensure that webdriver is loaded till the bottom of the page \n",
    "# before beautiful soup object is initialised to parse info\n",
    "def scrollToBottom():\n",
    "    # Pause time\n",
    "    SCROLL_PAUSE_TIME = 5\n",
    "\n",
    "    # Get scroll height\n",
    "    last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    for i in range(3):\n",
    "        # Sroll down to bottom\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "\n",
    "        # Wait to load page\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "        # Calculate new scroll height and compare with last scroll height\n",
    "        new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f23d17e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an instance of beautiful soup based on current browser page\n",
    "def buildSoup():\n",
    "    src = browser.page_source\n",
    "    soup = BeautifulSoup(src, 'lxml')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "da3e5ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract information while on a profile page\n",
    "def getInfo(soup):\n",
    "    \n",
    "    # Get name of person, title of their role\n",
    "    infoSection = soup.find(\"div\", {\"class\": \"ph5\"})\n",
    "    leftDiv = infoSection.find(\"div\", {\"class\": \"pv-text-details__left-panel\"})\n",
    "    name = leftDiv.find_all(\"div\")[0].find(\"h1\").text.strip()\n",
    "    title = leftDiv.find_all(\"div\")[1].text.strip()\n",
    "    \n",
    "    # Get organisation the person works in, location of their role\n",
    "    rightDiv = infoSection.find(\"ul\", {\"class\": \"pv-text-details__right-panel\"})\n",
    "    if rightDiv:\n",
    "        organisation = rightDiv.find(\"h2\").text.strip()\n",
    "        location = rightDiv.next_sibling.next_sibling.find(\"span\").text.strip()\n",
    "    \n",
    "    # Create information dictionary\n",
    "    if rightDiv:\n",
    "        infoDict = {\n",
    "            \"Name\": name,\n",
    "            \"Title\": title,\n",
    "            \"Organisation\": organisation,\n",
    "            \"Location\": location\n",
    "        }\n",
    "    else:\n",
    "        infoDict = {\n",
    "            \"Name\": name,\n",
    "            \"Title\": title\n",
    "        }\n",
    "    \n",
    "    # Get work experience of the person\n",
    "    exp = soup.find(lambda tag: tag.name == \"span\" and tag.text == \"Experience\")\n",
    "    if not exp:\n",
    "        return infoDict\n",
    "    \n",
    "    # Get work experience section\n",
    "    expSection = exp.find_parent(\"section\")\n",
    "    expMore = expSection.find(\"span\", {\"class\": \"pvs-navigation__text\"})\n",
    "    \n",
    "    # If there is \"more experience\" tab, click into tab\n",
    "    if expMore:\n",
    "        expMoreText = expMore.text.strip()\n",
    "        element = browser.find_element_by_link_text(expMoreText)\n",
    "        actions = ActionChains(browser)\n",
    "        actions.move_to_element(element).perform()\n",
    "        moreButton = WebDriverWait(browser, 20).until(\n",
    "                                EC.element_to_be_clickable((By.LINK_TEXT, expMoreText)))\n",
    "        moreButton.click()\n",
    "        exp = soup.find(lambda tag: tag.name == \"span\" and tag.text == \"Experience\")\n",
    "        expSection = exp.find_parent(\"section\")\n",
    "    \n",
    "    # Get list of experiences\n",
    "    expSection = expSection.find(\"ul\")\n",
    "    jobList = expSection.find_all(\"li\")\n",
    "    count = 1\n",
    "    \n",
    "    # Initialise a list to store information about their part jobs\n",
    "    for job in jobList:\n",
    "        jobTitle = job.find(\"span\", {\"class\": \"mr1 t-bold\"})\n",
    "        jobCompany = job.find(\"span\", {\"class\": \"t-14 t-normal\"})\n",
    "        jobPeriod = job.find(\"span\", {\"class\": \"t-14 t-normal t-black--light\"})\n",
    "        \n",
    "        if jobTitle:\n",
    "            jobTitle = jobTitle.find(\"span\").text\n",
    "            jobCompany = jobCompany.find(\"span\").text\n",
    "            jobCompany = jobCompany.split(\"Â·\")[0]\n",
    "            jobPeriod = jobPeriod.find(\"span\").text\n",
    "            jobString = \"Job \"+str(count)\n",
    "            infoDict[jobString+\" Title\"] = jobTitle\n",
    "            infoDict[jobString+\" Company\"] = jobCompany\n",
    "            infoDict[jobString+\" Period\"] =  jobPeriod\n",
    "            count += 1\n",
    "    \n",
    "    return infoDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "17007ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to store extracted information into a dataframe\n",
    "def storeDataFrame(infoDF, infoDict):\n",
    "    # Add extra row for each person into dictionary \n",
    "    new_row = pd.DataFrame(infoDict, index = [0])\n",
    "    infoDF = pd.concat([infoDF, new_row]).reset_index(drop = True)\n",
    "    return infoDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86cfb24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create link to connections list page\n",
    "def createLink(connectionHref):\n",
    "    connectionLink = \"https://www.linkedin.com/\" + connectionHref\n",
    "    return connectionLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5840d0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add connection urls to a queue\n",
    "def addProfile(profileQueue, connectionLink):\n",
    "    \n",
    "    # Access the connectionLink from initial link\n",
    "    browser.get(connectionLink)\n",
    "    \n",
    "    # Count number of connections\n",
    "    countConnections = 0\n",
    "    \n",
    "    # while loop that runs as long as there are extra pages of connections to access\n",
    "    while True:\n",
    "        scrollToBottom()\n",
    "        connectionSoup = buildSoup()\n",
    "        \n",
    "        connectionList = connectionSoup.find_all(\"span\", {\"class\": \"entity-result__title-text t-16\"})\n",
    "\n",
    "        for connection in connectionList:\n",
    "            connectionTag = connection.contents[1]\n",
    "            profileHref = connectionTag[\"href\"]\n",
    "            if profileHref not in profileQueue:\n",
    "                profileQueue.append(profileHref)\n",
    "        \n",
    "        countConnections += len(connectionList)\n",
    "        \n",
    "        try:\n",
    "            nextButton = WebDriverWait(browser, 20).until(\n",
    "                        EC.element_to_be_clickable((By.CLASS_NAME, \"artdeco-pagination__button--next\")))\n",
    "        except:\n",
    "            print(f\"---Final number of profiles in queue: {countConnections}---\")\n",
    "            return profileQueue;\n",
    "        print(f\"---Current number of profiles in queue: {countConnections}---\")\n",
    "        nextButton.click()\n",
    "            \n",
    "    return profileQueu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f016f2",
   "metadata": {},
   "source": [
    "Functions above used to extract information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "2a7e2e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise a dataframe to store information\n",
    "infoDF = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f4218fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise a queue for processing profiles\n",
    "profileQueue = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35386711",
   "metadata": {},
   "source": [
    "Input relevant starting page to access connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e89f01e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access link to personal page\n",
    "initialLink = \"https://www.linkedin.com/in/ching-hong-fung/\"\n",
    "\n",
    "# Access the initial link using webdriver\n",
    "browser.get(initialLink)\n",
    "\n",
    "# Scroll to bottom of page to access entire dom\n",
    "scrollToBottom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5e078f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ching Hong (Jacky) Fung', 'Software Developer Intern at BGC Partners | First-Class MEng Engineering Graduate from University of Oxford', 'BGC Partners', 'London, England, United Kingdom']\n"
     ]
    }
   ],
   "source": [
    "soup = buildSoup()\n",
    "infoList = getInfo(soup)\n",
    "print(infoList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4eae1f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a beautiful soup instance for current profile page\n",
    "soup = buildSoup()\n",
    "\n",
    "# Extract information from soup\n",
    "infoList = getInfo(soup)\n",
    "\n",
    "# Store information into data frame\n",
    "infoDF = storeDataFrame(infoDF, infoList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "52a16fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>Organisation</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ching Hong (Jacky) Fung</td>\n",
       "      <td>Software Developer Intern at BGC Partners | Fi...</td>\n",
       "      <td>BGC Partners</td>\n",
       "      <td>London, England, United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Name                                              Title  \\\n",
       "0  Ching Hong (Jacky) Fung  Software Developer Intern at BGC Partners | Fi...   \n",
       "\n",
       "   Organisation                         Location  \n",
       "0  BGC Partners  London, England, United Kingdom  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infoDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ea58a330",
   "metadata": {},
   "outputs": [],
   "source": [
    "profileQueue = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b536cb2d",
   "metadata": {},
   "source": [
    "#### Access connections to get information\n",
    "\n",
    "Use selenium functions to look through all connections and storing them into a list for individual profile extraction later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "47c549ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get link to list of connections\n",
    "connectionSpan = soup.find(\"span\", {\"class\": \"link-without-visited-state\"})\n",
    "connectionTag = connectionSpan.parent\n",
    "connectionHref = connectionTag[\"href\"]\n",
    "connectionLink = createLink(connectionHref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "655e9787",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Current number of profiles in queue: 10---\n",
      "---Current number of profiles in queue: 20---\n",
      "---Current number of profiles in queue: 30---\n",
      "---Current number of profiles in queue: 40---\n",
      "---Current number of profiles in queue: 50---\n",
      "---Current number of profiles in queue: 60---\n",
      "---Current number of profiles in queue: 70---\n",
      "---Current number of profiles in queue: 80---\n",
      "---Current number of profiles in queue: 90---\n",
      "---Current number of profiles in queue: 100---\n",
      "---Current number of profiles in queue: 110---\n",
      "---Current number of profiles in queue: 120---\n",
      "---Current number of profiles in queue: 130---\n",
      "---Current number of profiles in queue: 140---\n",
      "---Current number of profiles in queue: 150---\n",
      "---Current number of profiles in queue: 160---\n",
      "---Current number of profiles in queue: 170---\n",
      "---Current number of profiles in queue: 180---\n",
      "---Current number of profiles in queue: 190---\n",
      "---Current number of profiles in queue: 200---\n",
      "---Current number of profiles in queue: 210---\n",
      "---Current number of profiles in queue: 220---\n",
      "---Current number of profiles in queue: 230---\n",
      "---Current number of profiles in queue: 240---\n",
      "---Current number of profiles in queue: 250---\n",
      "---Current number of profiles in queue: 260---\n",
      "---Current number of profiles in queue: 270---\n",
      "---Current number of profiles in queue: 280---\n",
      "---Current number of profiles in queue: 290---\n",
      "---Current number of profiles in queue: 300---\n",
      "---Current number of profiles in queue: 310---\n",
      "---Final number of profiles in queue: 320---\n"
     ]
    }
   ],
   "source": [
    "# Get all connection urls\n",
    "profileQueue = addProfile(profileQueue, connectionLink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ac929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access each profile to extract information\n",
    "# for idx, profileUrl in enumerate(profileQueue):\n",
    "for profileUrl in profileQueue:\n",
    "    browser.get(profileUrl)\n",
    "    scrollToBottom()\n",
    "    \n",
    "    # Create a beautiful soup instance for current profile page\n",
    "    soup = buildSoup()\n",
    "\n",
    "    # Extract information from soup\n",
    "    infoDict = getInfo(soup)\n",
    "    print(f\"Processing {infoDict['Name']}'s profile\")\n",
    "\n",
    "    # Store information into data frame\n",
    "    infoDF = storeDataFrame(infoDF, infoList)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ba3b64",
   "metadata": {},
   "source": [
    "Export data into csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "aeb447ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "infoDF.to_csv('linkedin-info.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
